<div id="top"></div>


[![Contributors][contributors-shield]][contributors-url1]
[![Contributors][contributors-shield]][contributors-url2]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![LinkedIn][linkedin-shield]][linkedin-url]

<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/github_username/repo_name.svg?style=for-the-badge
[contributors-url1]: https://github.com/abdallah-elsawy
[contributors-url2]: https://github.com/tarekmoha
<!-- [contributors-url3]: https://github.com/abdallah-elsawy -->
[forks-shield]: https://img.shields.io/github/forks/github_username/repo_name.svg?style=for-the-badge
[forks-url]: https://github.com/AlaaSedeeq/Millan-Data-Imputation-And-Forecasting/fork
[stars-shield]: https://img.shields.io/github/stars/github_username/repo_name.svg?style=for-the-badge
[stars-url]: https://github.com/AlaaSedeeq/Millan-Data-Imputation-And-Forecasting/stargazers
[issues-shield]: https://img.shields.io/github/issues/github_username/repo_name.svg?style=for-the-badge
[issues-url]: https://github.com/AlaaSedeeq/Millan-Data-Imputation-And-Forecasting/issues
[license-shield]: https://img.shields.io/github/license/github_username/repo_name.svg?style=for-the-badge
[linkedin-url]: https://linkedin.com/in/alaa-sedeeq
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555

### Built With

* [Python](https://www.python.org/)
* [TensorFlow](https://www.tensorflow.org/)
* [Keras](https://keras.io/)

<p align="right">(<a href="#top">back to top</a>)</p>


<!-- TABLE OF CONTENTS -->
<details>
    <summary>Table of Contents</summary>
    <ol>
      <li><a href="#about-the-data">About The Data</a>      
      <li><a href="#built-with">Built With</a></li>
      <li><a href="#obj">Project Objective</a>
          <ul>
              <li><a href="#pre">Gathering and preprocessing the Data</a></li>
              <li><a href="#impute">Missing data imputation</a></li>
                  <ul>
                      <li><a href="#conven">Conventional Methods</a></li>
                      <li><a href="#proced">Procedure Methods</a></li>
                      <li><a href="#learn">Learnable Methods</a></li>
              </ul>
              <li><a href="#forecast">Data Forecasting</a></li>
              <ul>
                  <li><a href="#stat">Statistical Methods</a></li>
                  <li><a href="#ml">ML Methods</a></li>
                  <li><a href="#dl">DL Methods</a></li>
              </ul>
          </ul>
    </ol>
</details>


<!-- ABOUT THE PROJECT -->
## About The Data

This dataset provides information about the telecommunication activity over the city of Milano. The dataset is the result of a computation over the Call Detail Records (CDRs) generated by the Telecom Italia cellular network over the city of Milano. CDRs log the user activity for billing purposes and network management.

The dataset reports lines in the format above for 10,000 areas (organized in a regular grid) during a continued period of two months.
A preliminary description of the data is provided in a paper published in Scientific Data by Barlacchi et al. [Link](https://www.nature.com/articles/sdata201555). <br>While the paper presents the many datasets that were made available for the other challenges, only two are relevant to the above mentioned tasks:

<img src='Data preparation and imputaion/images/animation.gif' align='center'></img>
<p align="right">(<a href="#top">back to top</a>)</p>


<a id="obj"></a><h2>The objective of this project is:</h2>
<ul>
  <a id="pre"></a><h3> 1) Gathering and preprocessing the <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/EGZHFV">Telecommunications Millan Data</a></h3><br>
    <ul>
      <li> Read the txt-file as csv.
      <li> Group the data by time and grid.
      <li> Concatenate all the data in one DataFrame.
      <li> Convert the full data into a numpy array, where each sample is a (100, 100) matrix.
        <ul>
          <li> Each sample is a matrix which is the measurements for all grids at a specific time step.
          <li> Each value in the matrix is a measurement for one grid at a this time step.
        </ul>
    </ul>
  <a id="impute"></a><h3>2) Applying many missing data imputation methods to the data</h3><br>
  <ul>
      <li> Missing data imputation methodes :
          <ul>
              <a id="conven"></a><li> Conventional methods:
                  <ul>
                      <li> Ignore or deletion.
                      <li> Mean imputaion.
                      <li> Mode imputaion.
                      <li> Median imputaion.
                  </ul>
              <a id="proced"></a><li> Imputation procedure:
                  <ul>
                      <li> Last valid observation forward.
                      <li> Next valid observation forward.
                      <li> Interpolation.
                  </ul>
              <a id="learn"></a><li> Learnable methods:
                  <ul>
                      <li> KNN algorithm.
                      <li> AutoRegressive.
                      <li> Genitic algorithm.
                      <li> MICE algorithm.
                      <li> Least square SVM.
                      <li> GAIN.
                      <li> Conv-GAIN.
                  </ul>
          </ul>
    </ul>
    <a id="forecast"></a><h3>3) Time series Forecasting: </h3><br>
    <ul>
        <a id="stat"></a><li> Statistical methods:
            <ul>
                <li> Common Approaches:
                    <ul>
                        <li>Trend, Seasonal, Residual Decompositions:
                        <li> Seasonal Extraction in ARIMA Time Series (SEATS).
                        <li> Seasonal and Trend decomposition using Loess (STL). 
                        <li> Exponential smoothing:
                            <ul>
                                <li> Single Exponential Smoothing, or SES, for univariate data without trend or seasonality.
                                <li> Double Exponential Smoothing for univariate data with support for trends.
                                <li> Triple Exponential Smoothing, or Holt-Winters Exponential Smoothing, with support for both trends and seasonality.(TES)
                            </ul>
                        <li> Autoregressive Models (AR).
                        <li> Moving Average Models (MA).
                    </ul>
                <li> Boxâ€“Jenkins Approaches: 
                    <ul>
                        <li> ARIMA.
                        <li> SARIMA.
                    </ul>
            </ul>
        <a id="ml"></a><li> Machine Learning Methods
          <ul>
              <li> KNN.
              <li> SVR.
              <li> Linear Regression.
              <li> ElasticNet.
              <li> Lasso.
            </ul>
        <a id="dl"></a><li> Deep Learning Methods:
            <ul>
                <li> MLP.
                <li> CNN.
                <li> LSTM.
            </ul>
    </ul>
</ul>
